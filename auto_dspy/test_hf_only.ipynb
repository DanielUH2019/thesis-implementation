{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import evaluate\n",
    "import dspy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "# Load the dataset.\n",
    "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=30, test_size=0)\n",
    "\n",
    "colbertv2_wiki17_abstracts = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "dspy.settings.configure(rm=colbertv2_wiki17_abstracts)\n",
    "retrieve = dspy.Retrieve()\n",
    "p = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "contexts = [retrieve(x).passages for x in dataset.dev]\n",
    "predicted_answers = [p(question=x['question'], context=contexts[i][0])['answer'] for i, x in enumerate(dataset.dev)]\n",
    "answers = [x['answer'] for x in dataset.dev]\n",
    "\n",
    "acc = evaluate.load('exact_match').compute(references=answers, predictions=predicted_answers)\n",
    "\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pipeline(\"question-answering\", model=\"deepset/tinyroberta-squad2\")\n",
    "predicted_answers = [p(question=x['question'], context=contexts[i][0])['answer'] for i, x in enumerate(dataset.dev)]\n",
    "acc = evaluate.load('exact_match').compute(references=answers, predictions=predicted_answers)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7473/7473 [00:00<00:00, 58646.94it/s]\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 56264.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from dspy.datasets.gsm8k import GSM8K\n",
    "\n",
    "gsm8k = GSM8K()\n",
    "gsm8k.train = gsm8k.train[:30]\n",
    "gsm8k.dev = gsm8k.dev[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pipeline(\"question-answering\", model=\"deepset/tinyroberta-squad2\")\n",
    "contexts = [retrieve(x).passages for x in gsm8k.dev]\n",
    "answers = [x['answer'] for x in gsm8k.dev]\n",
    "predicted_answers = [p(question=x['question'], context=contexts[i][0])['answer'] for i, x in enumerate(gsm8k.dev)]\n",
    "acc = evaluate.load('exact_match').compute(references=answers, predictions=predicted_answers)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "predicted_answers = [p(question=x['question'], context=contexts[i][0])['answer'] for i, x in enumerate(gsm8k.dev)]\n",
    "acc = evaluate.load('exact_match').compute(references=answers, predictions=predicted_answers)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 72613.60it/s]\n",
      "100%|██████████| 25000/25000 [00:00<00:00, 71181.35it/s]\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imdb import Imdb\n",
    "\n",
    "# dataset = load_dataset(\"imdb\")\n",
    "dataset = Imdb()\n",
    "p = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "answers = [x['answer'] for x in dataset.dev]\n",
    "predicted_answers = []\n",
    "count = 0\n",
    "for x in dataset.dev:\n",
    "    try:\n",
    "        predicted_answers.append(p(x['text'])['label'])\n",
    "    except:\n",
    "        count+=1\n",
    "        predicted_answers.append('-1')\n",
    "\n",
    "# \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "acc = evaluate.load('exact_match').compute(references=answers, predictions=predicted_answers)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "predicted_answers = []\n",
    "count = 0\n",
    "for x in dataset.dev:\n",
    "    try:\n",
    "        predicted_answers.append(p(x['text'])['label'])\n",
    "    except:\n",
    "        count+=1\n",
    "        predicted_answers.append('-1')\n",
    "\n",
    "# \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "acc = evaluate.load('exact_match').compute(references=answers, predictions=predicted_answers)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
